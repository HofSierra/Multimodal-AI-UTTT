{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ec71b-5a2e-4363-8947-722d95273ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install fastapi uvicorn unsloth transformers pillow torch numpy pydantic nest_asyncio asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682df35d-2d4f-4d5b-bc25-d5ddddb10a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoProcessor\n",
    "from pydantic import BaseModel\n",
    "from PIL import Image as PILImage\n",
    "import torch, io, base64, json, re, nest_asyncio, uvicorn, asyncio\n",
    "import numpy as np\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c09d69-d85c-47d8-a2e1-508ad2205766",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "api = FastAPI()\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = MODEL_NAME,\n",
    "        max_seq_length = MAX_SEQ_LENGTH,\n",
    "        dtype = DTYPE,\n",
    "        load_in_4bit = True,\n",
    "        trust_remote_code = True\n",
    "    )\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "model.config.use_cache = False\n",
    "\n",
    "model.load_adapter(OUTPUT_DIR_V4)\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "class MoveRequest(BaseModel):\n",
    "    image_base64: str\n",
    "    player_turn: str\n",
    "    global_state: list\n",
    "\n",
    "def check_win(grid):\n",
    "    grid = np.array(grid)\n",
    "    for i in range(3):\n",
    "        if grid[i, 0] == grid[i, 1] == grid[i, 2] != 0: return grid[i, 0]\n",
    "        if grid[0, i] == grid[1, i] == grid[2, i] != 0: return grid[0, i]\n",
    "    if (grid[0, 0] == grid[1, 1] == grid[2, 2] != 0) or (grid[2, 0] == grid[1, 1] == grid[0, 2] != 0):\n",
    "        return grid[1, 1]\n",
    "    return -1 if np.all(grid != 0) else 0\n",
    "\n",
    "def reconstruct_board_matrix(global_state_list):\n",
    "    board_matrix = [[[[0 for _ in range(3)] for _ in range(3)] for _ in range(3)] for _ in range(3)]\n",
    "    global_status = [[0 for _ in range(3)] for _ in range(3)]\n",
    "    for cell in global_state_list:\n",
    "        g_r, g_c, l_r, l_c = cell['global_row'], cell['global_col'], cell['local_row'], cell['local_col']\n",
    "        board_matrix[g_r][g_c][l_r][l_c] = cell['player']\n",
    "    for g_r in range(3):\n",
    "        for g_c in range(3):\n",
    "            global_status[g_r][g_c] = check_win(board_matrix[g_r][g_c])\n",
    "    return board_matrix, global_status\n",
    "\n",
    "def get_unplayable_boards(global_status):\n",
    "    unplayable = []\n",
    "    for r in range(3):\n",
    "        for c in range(3):\n",
    "            if global_status[r][c] != 0:\n",
    "                unplayable.append({\"global_row\": r, \"global_col\": c})\n",
    "    return unplayable\n",
    "\n",
    "def render_ascii_board(global_state_list):\n",
    "    symbols = {0: '.', 1: 'X', 2: 'O'}\n",
    "    state_map = {(c['global_row'], c['global_col'], c['local_row'], c['local_col']): symbols.get(c['player'], '.') for c in global_state_list}\n",
    "    sections = []\n",
    "    for g_r in range(3):\n",
    "        for g_c in range(3):\n",
    "            s = [f\"=== Global Board [{g_r}, {g_c}] ===\", \"    0 1 2\", \"   -------\"]\n",
    "            for l_r in range(3):\n",
    "                row = [state_map.get((g_r, g_c, l_r, l_c), '.') for l_c in range(3)]\n",
    "                s.append(f\"{l_r} | \" + \" \".join(row))\n",
    "            sections.append(\"\\n\".join(s))\n",
    "    return \"\\n\\n\".join(sections)\n",
    "\n",
    "def parse_move_from_text(text):\n",
    "    match = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
    "    if match:\n",
    "        try: return json.loads(match.group(0).replace(\"'\", '\"'))\n",
    "        except: return None\n",
    "    return None\n",
    "\n",
    "def format_squares_to_str(squares_list):\n",
    "    if not squares_list:\n",
    "        return \"[]\"\n",
    "\n",
    "    formatted = []\n",
    "    for sq in squares_list:\n",
    "        if isinstance(sq, dict) and 'global_row' in sq and 'global_col' in sq:\n",
    "            formatted.append(f\"({sq['global_row']}, {sq['global_col']})\")\n",
    "\n",
    "    return \"[\" + \", \".join(formatted) + \"]\"\n",
    "\n",
    "@api.post(\"/predict_move\")\n",
    "async def predict_move(request: MoveRequest):\n",
    "    try:\n",
    "        img_bytes = base64.b64decode(request.image_base64)\n",
    "        image = PILImage.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
    "\n",
    "        _, global_status = reconstruct_board_matrix(request.global_state)\n",
    "        unplayable_boards = get_unplayable_boards(global_status)\n",
    "        unplayable_list_str = format_squares_to_str(unplayable_boards)\n",
    "        ascii_board = render_ascii_board(request.global_state)\n",
    "\n",
    "        system_content = (\n",
    "            f\"You are an expert Ultimate Tic-Tac-Toe player. \"\n",
    "            f\"Your goal is to identify the optimal, legal move based on the provided image and context. \"\n",
    "            f\"The final output must be **ONLY** a raw JSON object containing the chosen move.\"\n",
    "            f\"{{\\\"global_row\\\": r, \\\"global_col\\\": c, \\\"local_row\\\": lr, \\\"local_col\\\": lc}}.\"\n",
    "        )\n",
    "\n",
    "        user_prompt_text = (\n",
    "            f\"Player: {request.player_turn} (X=Player 1, O=Player 2)\\n\"\n",
    "            f\"Analyze the board state in the image and determine the optimal move.\\n\\n\"\n",
    "            f\"--- BOARD CONTEXT ---\\n\"\n",
    "            f\"**Allowed/Active Board:** The global board highlighted in **BRIGHT GREEN** in the image is the current active board constraint. If this board is already won/tied, you must select any other available board (Free Play).\\n\"\n",
    "            f\"**Unplayable Boards:** The following Global Boards are already WON or TIED and cannot be played: {unplayable_list_str}\\n\\n\"\n",
    "            f\"--- ASCII VISUALIZATION ---\\n\"\n",
    "            f\"Use this labeled diagram to cross-reference the image coordinates (0, 1, 2) with the piece locations and board status:\\n\"\n",
    "            f\"{ascii_board}\\n\\n\"\n",
    "            f\"CRITICAL RULE: The target local cell (local_row, local_col) MUST be **EMPTY** on the global board (global_row, global_col).\\n\"\n",
    "            f\"CRITICAL RULE: All output coordinates (global_row, global_col, local_row, local_col) MUST be **0, 1 or 2**.\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": system_content}]},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"image\": image},\n",
    "                    {\"type\": \"text\", \"text\": user_prompt_text},\n",
    "                ],\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        inputs = processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=128, do_sample=False, temperature=0.1)\n",
    "\n",
    "        response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        if \"assistant\" in response_text:\n",
    "            response_text = response_text.split(\"assistant\")[-1].strip()\n",
    "\n",
    "        move = parse_move_from_text(response_text)\n",
    "        if not move:\n",
    "            raise HTTPException(status_code=422, detail=f\"Model failed: {response_text}\")\n",
    "        return move\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6637d6-90f5-4ecb-91a5-7cc0f1b3aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = uvicorn.Config(\n",
    "        api, \n",
    "        host=\"0.0.0.0\", \n",
    "        port=8000, \n",
    "        log_level=\"info\",\n",
    "    )\n",
    "    server = uvicorn.Server(config)\n",
    "    \n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.create_task(server.serve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
