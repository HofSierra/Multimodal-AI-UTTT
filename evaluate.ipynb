{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7ac8dc-4f3c-4661-8ee3-09942f31e0a8",
   "metadata": {},
   "source": [
    "### Install dependances"
   ]
  },
  {
   "cell_type": "code",
   "id": "e21720f2-4a50-496e-a1eb-55b484e55638",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-12-03T12:25:07.862162Z",
     "start_time": "2025-12-03T12:24:32.910556Z"
    }
   },
   "source": "!pip install torch unsloth dataset transformers Pillow",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\r\n",
      "  Downloading torch-2.9.1-cp313-none-macosx_11_0_arm64.whl.metadata (30 kB)\r\n",
      "Collecting unsloth\r\n",
      "  Downloading unsloth-2025.11.6-py3-none-any.whl.metadata (64 kB)\r\n",
      "Collecting dataset\r\n",
      "  Downloading dataset-1.6.2-py2.py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\r\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.13/site-packages (12.0.0)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch) (3.20.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch) (80.9.0)\r\n",
      "Collecting sympy>=1.13.3 (from torch)\r\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting networkx>=2.5.1 (from torch)\r\n",
      "  Downloading networkx-3.6-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch) (2025.10.0)\r\n",
      "Collecting unsloth_zoo>=2025.11.6 (from unsloth)\r\n",
      "  Downloading unsloth_zoo-2025.11.6-py3-none-any.whl.metadata (32 kB)\r\n",
      "Collecting wheel>=0.42.0 (from unsloth)\r\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from unsloth) (25.0)\r\n",
      "Collecting torchvision (from unsloth)\r\n",
      "  Downloading torchvision-0.24.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (from unsloth) (2.3.4)\r\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from unsloth) (4.67.1)\r\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.13/site-packages (from unsloth) (7.1.3)\r\n",
      "Collecting tyro (from unsloth)\r\n",
      "  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.13/site-packages (from unsloth) (5.29.5)\r\n",
      "INFO: pip is looking at multiple versions of unsloth to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting unsloth\r\n",
      "  Downloading unsloth-2025.11.4-py3-none-any.whl.metadata (64 kB)\r\n",
      "  Downloading unsloth-2025.11.3-py3-none-any.whl.metadata (61 kB)\r\n",
      "  Downloading unsloth-2025.11.2-py3-none-any.whl.metadata (61 kB)\r\n",
      "  Downloading unsloth-2025.11.1-py3-none-any.whl.metadata (61 kB)\r\n",
      "  Downloading unsloth-2025.10.12-py3-none-any.whl.metadata (61 kB)\r\n",
      "  Downloading unsloth-2025.10.11-py3-none-any.whl.metadata (61 kB)\r\n",
      "  Downloading unsloth-2025.10.10-py3-none-any.whl.metadata (61 kB)\r\n",
      "INFO: pip is still looking at multiple versions of unsloth to determine which version is compatible with other requirements. This could take a while.\r\n",
      "  Downloading unsloth-2025.10.9-py3-none-any.whl.metadata (59 kB)\r\n",
      "  Downloading unsloth-2025.10.8-py3-none-any.whl.metadata (59 kB)\r\n",
      "  Downloading unsloth-2025.10.7-py3-none-any.whl.metadata (59 kB)\r\n",
      "  Downloading unsloth-2025.10.6-py3-none-any.whl.metadata (59 kB)\r\n",
      "  Downloading unsloth-2025.10.5-py3-none-any.whl.metadata (59 kB)\r\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\r\n",
      "  Downloading unsloth-2025.10.4-py3-none-any.whl.metadata (59 kB)\r\n",
      "  Downloading unsloth-2025.10.3-py3-none-any.whl.metadata (59 kB)\r\n",
      "  Downloading unsloth-2025.10.2-py3-none-any.whl.metadata (59 kB)\r\n",
      "  Downloading unsloth-2025.10.1-py3-none-any.whl.metadata (53 kB)\r\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\r\n",
      "  Downloading xformers-0.0.33.post1.tar.gz (14.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.8/14.8 MB\u001B[0m \u001B[31m4.6 MB/s\u001B[0m  \u001B[33m0:00:03\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25l\\^C\r\n",
      "\u001B[?25canceled\r\n",
      "\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "d1631e4e-0e75-4c45-a955-2cdc885c2b75",
   "metadata": {},
   "source": [
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "476e4123-e9f2-49ed-a1ba-1a57d7a0113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoProcessor\n",
    "from PIL import Image as PILImage\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e06a0ff-c7be-48f8-bb1b-1f5292806fea",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a27ba86-4888-4d98-b2a0-517c745f0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"unsloth/Qwen3-VL-8B-Instruct-unsloth-bnb-4bit\"\n",
    "DATASET_TEST_PATH = \"uttt_qwen_dataset/test.parquet\"\n",
    "MAX_SEQ_LENGTH = 2048\n",
    "DTYPE = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d47bbe-dcde-47c7-82be-b57cb2f61190",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b37f2b98-a69b-4e29-af20-a436fb1d819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vlm_model():\n",
    "    print(f\"Loading Model: {MODEL_NAME}\")\n",
    "\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = MODEL_NAME,\n",
    "        max_seq_length = MAX_SEQ_LENGTH,\n",
    "        dtype = DTYPE,\n",
    "        load_in_4bit = True,\n",
    "        trust_remote_code = True\n",
    "    )\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "    model.config.use_cache = False\n",
    "\n",
    "    print(\"Model and Tokenizer loaded successfully\")\n",
    "    return model, tokenizer, processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf34ce67-2e34-4db0-907f-8f638bd52649",
   "metadata": {},
   "source": [
    "### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04bdbce5-b902-4b7f-adbb-ea35122dabbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_baseline(model, tokenizer, processor, test_data_path):\n",
    "    \"\"\"\n",
    "    baseline evaluation on evaluation set, to test model's ability.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        test_data = load_dataset(\"parquet\", data_files={\"test\": test_data_path}, split=\"test\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading test dataset: {e}\")\n",
    "        return 0,0,0\n",
    "\n",
    "    # small sample to avoid long initial run time\n",
    "    sample_size = min(len(test_data),1000)\n",
    "    print(f\"\\nStarting baseline evaluation on {sample_size} samples\")\n",
    "\n",
    "    correct_moves = 0\n",
    "    correct_allowed_squares = 0\n",
    "    legal_move_count = 0\n",
    "    invalid_model_move = 0\n",
    "    total_similarity_score = 0\n",
    "    total_moves = 0\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        sample = test_data[i]\n",
    "\n",
    "        # --- Input Prep ---\n",
    "\n",
    "        # Extract text prompt\n",
    "        user_content = next(item for item in sample[\"messages\"] if item[\"role\"] == \"user\")[\"content\"]\n",
    "        user_prompt_text = next(item[\"text\"] for item in user_content if item[\"type\"] == \"text\")\n",
    "\n",
    "        # Extract ground truth move\n",
    "        assistant_response = next(item for item in sample[\"messages\"] if item[\"role\"] == \"assistant\")[\"content\"][0][\"text\"]\n",
    "        ground_truth_move = parse_move_from_text(assistant_response)\n",
    "        if ground_truth_move is None:\n",
    "            print(f\"Skipping sample {i}: Could not parse ground truth JSON.\")\n",
    "            continue\n",
    "\n",
    "        ground_truth_allowed_square = parse_square_from_text(assistant_response)\n",
    "        if ground_truth_allowed_square is None:\n",
    "            ground_truth_allowed_square = {\n",
    "                \"global_row\": -1,\n",
    "                \"global_col\": -1\n",
    "            }\n",
    "\n",
    "\n",
    "        legal_moves = sample[\"legal_moves\"]\n",
    "\n",
    "        image = sample[\"image\"].convert(\"RGB\")\n",
    "\n",
    "        simplified_prompt = (\n",
    "                \"\\n\\nAnswer in two sentences. Be Brief.\" +\n",
    "                \"\\n\\nOne Sentence will be the allowed board in the format: {\\\"global_row\\\": r, \\\"global_col\\\": c}\"+\n",
    "                \"\\n\\nThe second sentence will be the bext available move to play in the format: {\\\"global_row\\\": r, \\\"global_col\\\": c, \\\"local_row\\\": r, \\\"local_col\\\": c}.\" +\n",
    "                \"<|image|>\" +\n",
    "                user_prompt_text\n",
    "            # \"\\n\\nOutput only the coordinates of the green square as a JSON object: {\\\"global_row\\\": r, \\\"global_col\\\": c}\"\n",
    "            # \"{\\\"global_row\\\": r, \\\"global_col\\\": c, \\\"local_row\\\": r, \\\"local_col\\\": c}.\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": image,\n",
    "                    },\n",
    "                    {\"type\": \"text\", \"text\": simplified_prompt},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        inputs = processor.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "\n",
    "        # --- Model Inference ---\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=256, use_cache=True)\n",
    "        # Decode Output\n",
    "        response_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "        # remove input prompt to get just the response\n",
    "        response_text = response_text.split(\"<|im_start|>assistant\\n\")[-1].strip()\n",
    "\n",
    "        # --- Parse Model's Move Attempt ---\n",
    "        model_move = parse_move_from_text(response_text)\n",
    "\n",
    "        model_allowed_square = parse_allowed_square_from_text(response_text)\n",
    "\n",
    "        total_moves += 1\n",
    "        is_correct_move = compare_moves(model_move, ground_truth_move)\n",
    "        is_correct_allowed_square = compare_sqs(model_allowed_square, ground_truth_allowed_square)\n",
    "        is_legal = is_move_legal(model_move, legal_moves)\n",
    "        is_model_move_invalid = model_move_invalid(model_move)\n",
    "        similarity_score = move_similarity(model_move, ground_truth_move)\n",
    "\n",
    "        total_similarity_score += similarity_score\n",
    "\n",
    "        if is_correct_move:\n",
    "            correct_moves += 1\n",
    "\n",
    "        if is_correct_allowed_square:\n",
    "            correct_allowed_squares += 1\n",
    "\n",
    "        if is_legal:\n",
    "            legal_move_count += 1\n",
    "\n",
    "        if is_model_move_invalid:\n",
    "            invalid_model_move += 1\n",
    "\n",
    "        if i<5 or is_correct_move or not is_correct_move:\n",
    "            print(f\"\\nSample {i+1}\")\n",
    "            print(f\"Ground Truth Best Move: {ground_truth_move}\")\n",
    "            if ground_truth_allowed_square[\"global_row\"] == -1:\n",
    "                print(f\"Ground Truth Allowed Square: Any Board\")\n",
    "            print(\"-\" * 100)\n",
    "            print(f\"Model Move: {model_move}\")\n",
    "            print(f\"Model Allowed Square: {model_allowed_square}\")\n",
    "            print(f\"Move Result: {'CORRECT MOVE' if is_correct_move else 'INCORRECT MOVE'}\")\n",
    "            print(f\"Allowed Sqaure Result: {'CORRECT Sqaure' if is_correct_allowed_square else 'INCORRECT Square'}\")\n",
    "            print(f\"Move Similarity Score: {similarity_score}\")\n",
    "            print(f\"Move Allowed?: {'Legal Move' if is_legal else 'Illegal Move'}\")\n",
    "            print(f\"{'Invalid Model Move' if is_model_move_invalid else ''}\")\n",
    "\n",
    "    move_accuracy = (correct_moves / total_moves) * 100 if total_moves > 0 else 0\n",
    "    square_accuracy = (correct_allowed_squares / total_moves) * 100 if total_moves > 0 else 0\n",
    "    legal_move_accuracy = (legal_move_count/total_moves) * 100 if total_moves > 0 else 0\n",
    "    avg_similarity_score = total_similarity_score / total_moves\n",
    "    invalid_moves = invalid_model_move\n",
    "    return move_accuracy, square_accuracy, legal_move_accuracy, total_moves, invalid_moves, avg_similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423bef0-08d7-4127-b5c1-5d90887d4c1a",
   "metadata": {},
   "source": [
    "### Parsing Model Response to Evalute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550853aa-725e-4437-bc5f-d477f949729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_move_from_text(text):\n",
    "    # extract JSON dictionary from VLM output\n",
    "\n",
    "    match = re.search(r'\\{\\s*\"global_row\":\\s*\\d+,\\s*\"global_col\":\\s*\\d+,\\s*\"local_row\":\\s*\\d+,\\s*\"local_col\":\\s*\\d+\\s*}', text)\n",
    "    if match:\n",
    "        try:\n",
    "            move_str = match.group(0).replace('\"', '\\\"')\n",
    "            return json.loads(move_str)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "    return None\n",
    "\n",
    "def parse_square_from_text(text):\n",
    "    match = re.search(r'Allowed Square:\\s*\\[\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\]', text)\n",
    "    none_match = re.search(r'Allowed Sqaure:\\s*None', text)\n",
    "    if none_match:\n",
    "        return {\n",
    "            \"global_row\": -1,\n",
    "            \"global_col\": -1\n",
    "        }\n",
    "    if match:\n",
    "        try:\n",
    "            return {\n",
    "                \"global_row\": int(match.group(1)),\n",
    "                \"global_col\": int(match.group(2))\n",
    "            }\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def parse_allowed_square_from_text(text):\n",
    "    match = re.search(r'\\{\\s*\"global_row\":\\s*(\\d+),\\s*\"global_col\":\\s*(\\d+)\\s*\\}', text)\n",
    "    if match:\n",
    "        try:\n",
    "            move_str = f'{{\"global_row\": {match.group(1)}, \"global_col\": {match.group(2)}}}'\n",
    "            return json.loads(move_str)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def compare_moves(model_move, ground_truth_move):\n",
    "    # compare model move against ground truth\n",
    "    if model_move is None:\n",
    "        return False\n",
    "\n",
    "    keys = [\"global_row\", \"global_col\", \"local_row\", \"local_col\"]\n",
    "\n",
    "    try:\n",
    "        return all(model_move.get(k) == ground_truth_move.get(k) for k in keys)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def compare_sqs(model_square, ground_truth_square):\n",
    "    # compare model move against ground truth\n",
    "    if model_square is None:\n",
    "        return False\n",
    "    if ground_truth_square.get(\"global_row\") == -1:\n",
    "        return True\n",
    "\n",
    "    keys = [\"global_row\", \"global_col\"]\n",
    "\n",
    "    try:\n",
    "        return all(model_square.get(k) == ground_truth_square.get(k) for k in keys)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def is_move_legal(model_move, legal_moves):\n",
    "    if model_move is None:\n",
    "        return False\n",
    "    for m in legal_moves:\n",
    "        if (\n",
    "                model_move[\"global_row\"] == m[\"global_row\"] and\n",
    "                model_move[\"global_col\"] == m[\"global_col\"] and\n",
    "                model_move[\"local_row\"] == m[\"local_row\"] and\n",
    "                model_move[\"local_col\"] == m[\"local_col\"]\n",
    "        ):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def model_move_invalid(model_move):\n",
    "    if model_move is None:\n",
    "        return True\n",
    "    required_keys = ['global_row', 'global_col', 'local_row', 'local_col']\n",
    "    if not all(key in model_move for key in required_keys):\n",
    "        return True\n",
    "    coordinates = [\n",
    "        model_move.get('global_row'),\n",
    "        model_move.get('global_col'),\n",
    "        model_move.get('local_row'),\n",
    "        model_move.get('local_col'),\n",
    "    ]\n",
    "\n",
    "    for coord in coordinates:\n",
    "        if not isinstance(coord, int) or coord not in {0, 1, 2}:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def move_similarity(model_move, ground_truth_move):\n",
    "    score = 0\n",
    "    if model_move is None:\n",
    "        return 0.0\n",
    "\n",
    "    keys = [\"global_row\", \"global_col\", \"local_row\", \"local_col\"]\n",
    "    if not all(key in model_move for key in keys):\n",
    "        return 0.0\n",
    "\n",
    "    if model_move[\"global_row\"] == ground_truth_move[\"global_row\"]:\n",
    "        score += 1\n",
    "    if model_move[\"global_col\"] == ground_truth_move[\"global_col\"]:\n",
    "        score += 1\n",
    "    if model_move[\"local_row\"] == ground_truth_move[\"local_row\"]:\n",
    "        score += 1\n",
    "    if model_move[\"local_col\"] == ground_truth_move[\"local_col\"]:\n",
    "        score += 1\n",
    "    return score / 4.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20973c9-77df-47f9-a44b-1e9c9917fe01",
   "metadata": {},
   "source": [
    "### Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b581ca12-9118-409d-b568-8fbe7c08d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer, processor = load_vlm_model()\n",
    "    move_accuracy, square_accuracy, legal_move_accuracy, total_samples, invalid_moves, avg_similarity_score = evaluate_baseline(model, tokenizer, processor, DATASET_TEST_PATH)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"BASELINE EVALUATION RESULTS\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Baseline Move Accuracy: {move_accuracy:.2f}%\")\n",
    "    print(f\"Baseline Allowed Square Accuracy: {square_accuracy:.2f}%\")\n",
    "    print(f\"Average Move Similarity Score: {avg_similarity_score}\")\n",
    "    print(f\"Baseline Legal Move Accuracy: {legal_move_accuracy:.2f}%\")\n",
    "    print(f\"Invalid Moves by Model (Hallucination/Out-of-bounds): {invalid_moves} moves\")\n",
    "    print(\"\\n\" + \"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
