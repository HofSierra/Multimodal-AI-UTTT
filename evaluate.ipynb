{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7ac8dc-4f3c-4661-8ee3-09942f31e0a8",
   "metadata": {},
   "source": "### Install dependencies"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e21720f2-4a50-496e-a1eb-55b484e55638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install torch unsloth dataset transformers pillow scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1631e4e-0e75-4c45-a955-2cdc885c2b75",
   "metadata": {},
   "source": [
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "476e4123-e9f2-49ed-a1ba-1a57d7a0113f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Your Flash Attention 2 installation seems to be broken?\n",
      "A possible explanation is you have a new CUDA version which isn't\n",
      "yet compatible with FA2? Please file a ticket to Unsloth or FA2.\n",
      "We shall now use Xformers instead, which does not have any performance hits!\n",
      "We found this negligible impact by benchmarking on 1x A100.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import torch, json, random, re\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoProcessor\n",
    "from tqdm import tqdm\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d47bbe-dcde-47c7-82be-b57cb2f61190",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37f2b98-a69b-4e29-af20-a436fb1d819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vlm_model():\n",
    "    global model, tokenizer, processor\n",
    "    print(f\"Loading Model: {MODEL_NAME}\")\n",
    "\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = MODEL_NAME,\n",
    "        max_seq_length = 4096,\n",
    "        dtype = None,\n",
    "        load_in_4bit = True,\n",
    "    )\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(MODEL_NAME)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "    print(\"Model and Tokenizer loaded successfully\")\n",
    "    return model, tokenizer, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e52169-ff9e-476a-930b-f488f82a4ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_content(text):\n",
    "    try:\n",
    "        match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "        if match:\n",
    "            return json.loads(match.group(0))\n",
    "            \n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def generate_response(model, processor, tokenizer, image, system, user):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": system}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": user}, {\"type\": \"image\"}]}\n",
    "    ]\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = processor(text=[text], images=[image], padding=True, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=512,\n",
    "            do_sample=False, \n",
    "            temperature=0.1,\n",
    "            repetition_penalty=1.1\n",
    "        )\n",
    "    \n",
    "    gen_ids = [out[len(inp):] for inp, out in zip(inputs.input_ids, outputs)]\n",
    "    return tokenizer.decode(gen_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de93a79a-f4b1-4d4a-8e12-2c5c18aeac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(model, tokenizer, processor, test_data_path):\n",
    "    try:\n",
    "        dataset = load_dataset(\"parquet\", data_files={\"test\": test_data_path}, split=\"test\")\n",
    "    except Exception as e: print(f\"Error: {e}\"); return\n",
    "\n",
    "    num_samples = len(dataset)\n",
    "    print(f\"\\n--- STARTING EVAL ON {num_samples} SAMPLES ---\\n\")\n",
    "\n",
    "    metrics = {\n",
    "        \"json_success\": 0, \"total_tasks\": 0,\n",
    "        \"move_active_grid\": 0, \"move_legal\": 0, \"move_exact\": 0, \"total_move\": 0,\n",
    "        \"state_similarity\": 0, \"state_exact\": 0, \"total_state\": 0, \n",
    "        \"legality_acc\": 0, \"total_legality\": 0,\n",
    "        \"active_grid_task_acc\": 0, \"total_active_task\": 0\n",
    "    }\n",
    "\n",
    "    sys_prompt = (\"You are an Ultimate Tic-Tac-Toe Visual Engine. **STRICT PROTOCOL:**\\n\"\n",
    "                  \"1. FORMAT: All responses must be valid JSON snippets wrapped in JSON_START/JSON_END anchors.\\n\"\n",
    "                  \"2. COORDINATES: Use 0-indexed integers (0, 1, 2) for all Row/Col values.\\n\"\n",
    "                  \"3. VISUAL ANCHOR: The allowed square (active subgrid) is highlighted in GREEN. You must play there.\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i in tqdm(range(num_samples)):\n",
    "        sample = dataset[i]\n",
    "        image = sample[\"image\"].convert(\"RGB\")\n",
    "        p_char = \"X\" if sample[\"player\"] == 1 else \"O\"\n",
    "        \n",
    "        gt_allowed = sample.get(\"allowed_squares\")\n",
    "        legal_list = sample[\"legal_moves\"]\n",
    "        gt_best = sample[\"best_move\"]\n",
    "        full_state = sample[\"global_state\"]\n",
    "        \n",
    "        gr, gc = random.randint(0, 2), random.randint(0, 2)\n",
    "\n",
    "        is_legal_truth = any(m['global_row'] == gr and m['global_col'] == gc and m['local_row'] == 1 and m['local_col'] == 1 for m in legal_list)\n",
    "\n",
    "        tasks = [\n",
    "            (\"ALLOWED_SQUARE\", \"Identify the allowed square (active global subgrid) based on the green highlight. If none is highlighted, report null.\"),\n",
    "            (\"MOVE\", f\"Visually analyze the board. It is Player {p_char}'s turn. Identify the allowed square (green highlight) and then select the best move.\"),\n",
    "            (\"STATE\", f\"Examine Global Subgrid ({gr}, {gc}). Represent the 3x3 local grid state as a matrix of 'X', 'O', or '.' (Empty).\"),\n",
    "            (\"LEGALITY\", f\"Is it legal for Player {p_char} to play at Global({gr},{gc}), Local(1,1)? Step 1: Inspect the square state. Step 2: Check allowed square constraint. Step 3: Verdict.\"),\n",
    "        ]\n",
    "        \n",
    "        def check_allowed(pred):\n",
    "            if gt_allowed is None or len(gt_allowed) < 2:\n",
    "                return pred is None or pred == \"null\"\n",
    "            if not pred: return False \n",
    "            if isinstance(pred, dict): return pred.get(\"global_row\") == gt_allowed[0] and pred.get(\"global_col\") == gt_allowed[1]\n",
    "            return False\n",
    "\n",
    "        gt_matrix = []\n",
    "        for lr in range(3):\n",
    "            row = []\n",
    "            for lc in range(3):\n",
    "                occ = next((p['player'] for p in full_state if p['global_row'] == gr and p['global_col'] == gc and p['local_row'] == lr and p['local_col'] == lc), 0)\n",
    "                row.append(\"X\" if occ == 1 else \"O\" if occ == 2 else \".\")\n",
    "            gt_matrix.append(row)\n",
    "\n",
    "        for task_name, prompt in tasks:\n",
    "            metrics[\"total_tasks\"] += 1\n",
    "            \n",
    "            try:\n",
    "                resp = generate_response(model, processor, tokenizer, image, sys_prompt, prompt)\n",
    "                parsed = extract_json_content(resp)\n",
    "            except:\n",
    "                parsed = None\n",
    "\n",
    "            if parsed: metrics[\"json_success\"] += 1\n",
    "            else: continue\n",
    "\n",
    "            if task_name == \"ALLOWED_SQUARE\":\n",
    "                metrics[\"total_active_task\"] += 1\n",
    "                pred = parsed.get(\"allowed_square\")\n",
    "                if check_allowed(pred): metrics[\"active_grid_task_acc\"] += 1\n",
    "\n",
    "            elif task_name == \"MOVE\":\n",
    "                metrics[\"total_move\"] += 1\n",
    "                pred_allowed = parsed.get(\"allowed_square\")\n",
    "                if check_allowed(pred_allowed): metrics[\"move_active_grid\"] += 1\n",
    "                \n",
    "                pm = parsed.get(\"move\") or parsed.get(\"best_move\")\n",
    "                if isinstance(pm, dict):\n",
    "                    pr, pc, plr, plc = pm.get(\"global_row\"), pm.get(\"global_col\"), pm.get(\"local_row\"), pm.get(\"local_col\")\n",
    "                    if pr is not None:\n",
    "                        is_legal = any(m['global_row']==pr and m['global_col']==pc and m['local_row']==plr and m['local_col']==plc for m in legal_list)\n",
    "                        if is_legal: metrics[\"move_legal\"] += 1\n",
    "                        \n",
    "                        if pr==gt_best['global_row'] and pc==gt_best['global_col'] and plr==gt_best['local_row'] and plc==gt_best['local_col']:\n",
    "                            metrics[\"move_exact\"] += 1\n",
    "\n",
    "            elif task_name == \"STATE\":\n",
    "                metrics[\"total_state\"] += 1\n",
    "                pm = parsed.get(\"grid_matrix\")\n",
    "                \n",
    "                if pm == gt_matrix: metrics[\"state_exact\"] += 1\n",
    "                if pm and isinstance(pm, list) and len(pm) == 3:\n",
    "                    matches = 0\n",
    "                    for r in range(3):\n",
    "                        for c in range(3):\n",
    "                            if len(pm[r]) > c and pm[r][c] == gt_matrix[r][c]: matches += 1\n",
    "                    score = matches / 9.0\n",
    "                    metrics[\"state_similarity\"] += score\n",
    "\n",
    "            elif task_name == \"LEGALITY\":\n",
    "                metrics[\"total_legality\"] += 1\n",
    "                pl = parsed.get(\"is_legal\") \n",
    "                if pl is not None:\n",
    "                    if pl == is_legal_truth: metrics[\"legality_acc\"] += 1\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"JSON Syntax:     {metrics['json_success']/max(1, metrics['total_tasks'])*100:.1f}%\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"[ALLOWED] Acc:   {metrics['active_grid_task_acc']/max(1, metrics['total_active_task'])*100:.1f}%\")\n",
    "    print(f\"[MOVE] Legal:    {metrics['move_legal']/max(1, metrics['total_move'])*100:.1f}%\")\n",
    "    print(f\"[MOVE] Exact:    {metrics['move_exact']/max(1, metrics['total_move'])*100:.1f}%\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"[STATE] Exact:   {metrics['state_exact']/max(1, metrics['total_state'])*100:.1f}%\")\n",
    "    print(f\"[STATE] Sim %:   {(metrics['state_similarity']/max(1, metrics['total_state']))*100:.1f}%\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"[LEGAL] Logic:   {metrics['legality_acc']/max(1, metrics['total_legality'])*100:.1f}%\")\n",
    "    print(\"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ced2ecb-370f-4627-b7b7-be505feb094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_debug_eval(model, tokenizer, processor, test_data_path, num_samples=5):\n",
    "    print(f\"\\n--- STARTING EVAL ON {num_samples} SAMPLES ---\\n\")\n",
    "    try:\n",
    "        dataset = load_dataset(\"parquet\", data_files={\"test\": test_data_path}, split=\"test\")\n",
    "        dataset = dataset.shuffle(seed=42).select(range(min(num_samples, len(dataset))))\n",
    "    except Exception as e: print(f\"Error: {e}\"); return\n",
    "\n",
    "    metrics = {\n",
    "        \"json_success\": 0, \"total_tasks\": 0,\n",
    "        \"move_active_grid\": 0, \"move_legal\": 0, \"move_exact\": 0, \"total_move\": 0,\n",
    "        \"state_similarity\": 0, \"state_exact\": 0, \"total_state\": 0, \n",
    "        \"legality_acc\": 0, \"total_legality\": 0,\n",
    "        \"active_grid_task_acc\": 0, \"total_active_task\": 0\n",
    "    }\n",
    "\n",
    "    sys_prompt = (\"You are an Ultimate Tic-Tac-Toe Visual Engine. **STRICT PROTOCOL:**\\n\"\n",
    "                  \"1. FORMAT: All responses must be valid JSON snippets wrapped in JSON_START/JSON_END anchors.\\n\"\n",
    "                  \"2. COORDINATES: Use 0-indexed integers (0, 1, 2) for all Row/Col values.\\n\"\n",
    "                  \"3. VISUAL ANCHOR: The allowed square (active subgrid) is highlighted in GREEN. You must play there.\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        sample = dataset[i]\n",
    "        image = sample[\"image\"].convert(\"RGB\")\n",
    "        p_char = \"X\" if sample[\"player\"] == 1 else \"O\"\n",
    "        \n",
    "        gt_allowed = sample.get(\"allowed_squares\")\n",
    "        legal_list = sample[\"legal_moves\"]\n",
    "        gt_best = sample[\"best_move\"]\n",
    "        full_state = sample[\"global_state\"]\n",
    "        ascii_board = sample.get(\"ascii_board\", \"No ASCII available\")\n",
    "\n",
    "        gr, gc = random.randint(0, 2), random.randint(0, 2)\n",
    "\n",
    "        print(f\"\\n{'='*20} SAMPLE {i} {'='*20}\")\n",
    "        print(f\"Player: {p_char} | GT Allowed: {gt_allowed}\")\n",
    "        print(ascii_board)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        is_legal_truth = any(m['global_row'] == gr and m['global_col'] == gc and m['local_row'] == 1 and m['local_col'] == 1 for m in legal_list)\n",
    "\n",
    "        tasks = [\n",
    "            (\"ALLOWED_SQUARE\", \"Identify the allowed square (active global subgrid) based on the green highlight. If none is highlighted, report null.\"),\n",
    "            (\"MOVE\", f\"Visually analyze the board. It is Player {p_char}'s turn. Identify the allowed square (green highlight) and then select the best move.\"),\n",
    "            (\"STATE\", f\"Examine Global Subgrid ({gr}, {gc}). Represent the 3x3 local grid state as a matrix of 'X', 'O', or '.' (Empty).\"),\n",
    "            (\"LEGALITY\", f\"Is it legal for Player {p_char} to play at Global({gr},{gc}), Local(1,1)? Step 1: Inspect the square state. Step 2: Check allowed square constraint. Step 3: Verdict.\"),\n",
    "        ]\n",
    "        \n",
    "        def check_allowed(pred):\n",
    "            if gt_allowed is None or len(gt_allowed) < 2:\n",
    "                return pred is None or pred == \"null\"\n",
    "            if not pred: return False \n",
    "            if isinstance(pred, dict): return pred.get(\"global_row\") == gt_allowed[0] and pred.get(\"global_col\") == gt_allowed[1]\n",
    "            return False\n",
    "\n",
    "        gt_matrix = []\n",
    "        for lr in range(3):\n",
    "            row = []\n",
    "            for lc in range(3):\n",
    "                occ = next((p['player'] for p in full_state if p['global_row'] == gr and p['global_col'] == gc and p['local_row'] == lr and p['local_col'] == lc), 0)\n",
    "                row.append(\"X\" if occ == 1 else \"O\" if occ == 2 else \".\")\n",
    "            gt_matrix.append(row)\n",
    "\n",
    "        for task_name, prompt in tasks:\n",
    "            metrics[\"total_tasks\"] += 1\n",
    "            print(f\"[{task_name}] Prompt: {prompt}\")\n",
    "            \n",
    "            resp = generate_response(model, processor, tokenizer, image, sys_prompt, prompt)\n",
    "            print(f\"[{task_name}] Raw Response:\\n{resp}\\n\")\n",
    "            \n",
    "            parsed = extract_json_content(resp)\n",
    "            if parsed: metrics[\"json_success\"] += 1\n",
    "            else: \n",
    "                print(f\"!!! JSON PARSE FAILED for {task_name} !!!\")\n",
    "                continue\n",
    "\n",
    "            if task_name == \"ALLOWED_SQUARE\":\n",
    "                metrics[\"total_active_task\"] += 1\n",
    "                pred = parsed.get(\"allowed_square\")\n",
    "                if check_allowed(pred): metrics[\"active_grid_task_acc\"] += 1\n",
    "                else: print(f\"-> ALLOWED SQ FAIL. GT: {gt_allowed}, Pred: {pred}\")\n",
    "\n",
    "            elif task_name == \"MOVE\":\n",
    "                metrics[\"total_move\"] += 1\n",
    "                pred_allowed = parsed.get(\"allowed_square\")\n",
    "                if check_allowed(pred_allowed): metrics[\"move_active_grid\"] += 1\n",
    "                \n",
    "                pm = parsed.get(\"move\") or parsed.get(\"best_move\")\n",
    "                if isinstance(pm, dict):\n",
    "                    pr, pc, plr, plc = pm.get(\"global_row\"), pm.get(\"global_col\"), pm.get(\"local_row\"), pm.get(\"local_col\")\n",
    "                    if pr is not None:\n",
    "                        is_legal = any(m['global_row']==pr and m['global_col']==pc and m['local_row']==plr and m['local_col']==plc for m in legal_list)\n",
    "                        if is_legal: metrics[\"move_legal\"] += 1\n",
    "                        else: print(f\"-> ILLEGAL MOVE: {pm}\")\n",
    "                        \n",
    "                        if pr==gt_best['global_row'] and pc==gt_best['global_col'] and plr==gt_best['local_row'] and plc==gt_best['local_col']:\n",
    "                            metrics[\"move_exact\"] += 1\n",
    "\n",
    "            elif task_name == \"STATE\":\n",
    "                metrics[\"total_state\"] += 1\n",
    "                pm = parsed.get(\"grid_matrix\")\n",
    "                \n",
    "                if pm == gt_matrix: metrics[\"state_exact\"] += 1\n",
    "                if pm and isinstance(pm, list) and len(pm) == 3:\n",
    "                    matches = 0\n",
    "                    for r in range(3):\n",
    "                        for c in range(3):\n",
    "                            if len(pm[r]) > c and pm[r][c] == gt_matrix[r][c]: matches += 1\n",
    "                    score = matches / 9.0\n",
    "                    metrics[\"state_similarity\"] += score\n",
    "                    if score < 1.0: print(f\"-> STATE PARTIAL ({int(score*100)}%). GT: {gt_matrix} vs Pred: {pm}\")\n",
    "\n",
    "            elif task_name == \"LEGALITY\":\n",
    "                metrics[\"total_legality\"] += 1\n",
    "                pl = parsed.get(\"is_legal\") \n",
    "                if pl is not None:\n",
    "                    if pl == is_legal_truth: metrics[\"legality_acc\"] += 1\n",
    "                    else: print(f\"-> LEGALITY FAIL. GT: {is_legal_truth}, Pred: {pl}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"JSON Syntax:     {metrics['json_success']/metrics['total_tasks']*100:.1f}%\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"[ALLOWED] Acc:   {metrics['active_grid_task_acc']/metrics['total_active_task']*100:.1f}%\")\n",
    "    print(f\"[MOVE] Legal:    {metrics['move_legal']/metrics['total_move']*100:.1f}%\")\n",
    "    print(f\"[MOVE] Exact:    {metrics['move_exact']/metrics['total_move']*100:.1f}%\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"[STATE] Exact:   {metrics['state_exact']/metrics['total_state']*100:.1f}%\")\n",
    "    print(f\"[STATE] Sim %:   {(metrics['state_similarity']/metrics['total_state'])*100:.1f}%\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"[LEGAL] Logic:   {metrics['legality_acc']/metrics['total_legality']*100:.1f}%\")\n",
    "    print(\"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80ee5244-844c-47b9-bbcf-849399ae9487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model: unsloth/Qwen3-VL-8B-Instruct-unsloth-bnb-4bit\n",
      "==((====))==  Unsloth 2026.1.4: Fast Qwen3_Vl patching. Transformers: 4.57.6.\n",
      "   \\\\   /|    NVIDIA A100 80GB PCIe MIG 1g.20gb. Num GPUs = 1. Max memory: 19.5 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6a6e11aa3a41849e4f3dcecd2f0faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Tokenizer loaded successfully\n",
      "\n",
      "--- STARTING EVAL ON 5 SAMPLES ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [4:51:26<00:00, 43.72s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "JSON Syntax:     100.0%\n",
      "----------------------------------------\n",
      "[ALLOWED] Acc:   100.0%\n",
      "[MOVE] Legal:    93.8%\n",
      "[MOVE] Exact:    13.2%\n",
      "----------------------------------------\n",
      "[STATE] Exact:   82.5%\n",
      "[STATE] Sim %:   92.0%\n",
      "----------------------------------------\n",
      "[LEGAL] Logic:   95.0%\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer, processor = load_vlm_model()\n",
    "    model.load_adapter(OUTPUT_DIR_V2)\n",
    "    run_eval(model, tokenizer, processor, DATASET_TEST_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
