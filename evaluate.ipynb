{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7ac8dc-4f3c-4661-8ee3-09942f31e0a8",
   "metadata": {},
   "source": [
    "### Install dependances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e21720f2-4a50-496e-a1eb-55b484e55638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://nexus.iisys.de/repository/ki-awz-pypi-group/simple, https://pypi.org/simple\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: unsloth in /opt/conda/lib/python3.12/site-packages (2025.12.8)\n",
      "Requirement already satisfied: dataset in /opt/conda/lib/python3.12/site-packages (1.6.2)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.57.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.12/site-packages (11.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /opt/conda/lib/python3.12/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: unsloth_zoo>=2025.12.6 in /opt/conda/lib/python3.12/site-packages (from unsloth) (2025.12.6)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.12/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from unsloth) (25.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (from unsloth) (0.24.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from unsloth) (2.2.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from unsloth) (7.0.0)\n",
      "Requirement already satisfied: tyro in /opt/conda/lib/python3.12/site-packages (from unsloth) (1.0.3)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.12/site-packages (from unsloth) (6.31.1)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in /opt/conda/lib/python3.12/site-packages (from unsloth) (0.0.33.post2)\n",
      "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /opt/conda/lib/python3.12/site-packages (from unsloth) (0.49.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from unsloth) (0.2.1)\n",
      "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /opt/conda/lib/python3.12/site-packages (from unsloth) (4.3.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /opt/conda/lib/python3.12/site-packages (from unsloth) (1.12.0)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from unsloth) (0.18.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /opt/conda/lib/python3.12/site-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: hf_transfer in /opt/conda/lib/python3.12/site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /opt/conda/lib/python3.12/site-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: trl!=0.19.0,<=0.24.0,>=0.18.2 in /opt/conda/lib/python3.12/site-packages (from unsloth) (0.24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.3.2)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.12.15)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.10.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
      "Requirement already satisfied: sqlalchemy<2.0.0,>=1.3.2 in /opt/conda/lib/python3.12/site-packages (from dataset) (1.4.54)\n",
      "Requirement already satisfied: alembic>=0.6.2 in /opt/conda/lib/python3.12/site-packages (from dataset) (1.16.5)\n",
      "Requirement already satisfied: banal>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from dataset) (1.0.6)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (3.2.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.20.1)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.12/site-packages (from alembic>=0.6.2->dataset) (1.3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: torchao>=0.13.0 in /opt/conda/lib/python3.12/site-packages (from unsloth_zoo>=2025.12.6->unsloth) (0.15.0)\n",
      "Requirement already satisfied: cut_cross_entropy in /opt/conda/lib/python3.12/site-packages (from unsloth_zoo>=2025.12.6->unsloth) (25.1.1)\n",
      "Requirement already satisfied: msgspec in /opt/conda/lib/python3.12/site-packages (from unsloth_zoo>=2025.12.6->unsloth) (0.20.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.3.1)\n",
      "Requirement already satisfied: importlib_metadata in /opt/conda/lib/python3.12/site-packages (from diffusers->unsloth) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.12/site-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.17.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /opt/conda/lib/python3.12/site-packages (from tyro->unsloth) (0.17.0)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /opt/conda/lib/python3.12/site-packages (from tyro->unsloth) (4.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch unsloth dataset transformers pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1631e4e-0e75-4c45-a955-2cdc885c2b75",
   "metadata": {},
   "source": [
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "476e4123-e9f2-49ed-a1ba-1a57d7a0113f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Your Flash Attention 2 installation seems to be broken?\n",
      "A possible explanation is you have a new CUDA version which isn't\n",
      "yet compatible with FA2? Please file a ticket to Unsloth or FA2.\n",
      "We shall now use Xformers instead, which does not have any performance hits!\n",
      "We found this negligible impact by benchmarking on 1x A100.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoProcessor\n",
    "from PIL import Image as PILImage\n",
    "import json\n",
    "import re\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d47bbe-dcde-47c7-82be-b57cb2f61190",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37f2b98-a69b-4e29-af20-a436fb1d819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vlm_model():\n",
    "    print(f\"Loading Model: {MODEL_NAME}\")\n",
    "\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = MODEL_NAME,\n",
    "        max_seq_length = MAX_SEQ_LENGTH,\n",
    "        dtype = DTYPE,\n",
    "        load_in_4bit = True,\n",
    "        trust_remote_code = True\n",
    "    )\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "    model.config.use_cache = False\n",
    "\n",
    "    print(\"Model and Tokenizer loaded successfully\")\n",
    "    return model, tokenizer, processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf34ce67-2e34-4db0-907f-8f638bd52649",
   "metadata": {},
   "source": [
    "### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04bdbce5-b902-4b7f-adbb-ea35122dabbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_baseline(model, tokenizer, processor, test_data_path):\n",
    "    \"\"\"\n",
    "    baseline evaluation on evaluation set, to test model's ability.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        test_data = load_dataset(\"parquet\", data_files={\"test\": test_data_path}, split=\"test\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading test dataset: {e}\")\n",
    "        return 0,0,0\n",
    "\n",
    "    # small sample to avoid long initial run time\n",
    "    sample_size = min(len(test_data), 5)\n",
    "    print(f\"\\nDataset size: {len(test_data)}\")\n",
    "    print(f\"Starting baseline evaluation on {sample_size} samples\")\n",
    "\n",
    "    correct_moves = 0\n",
    "    correct_allowed_squares = 0\n",
    "    legal_move_count = 0\n",
    "    invalid_model_move = 0\n",
    "    total_similarity_score = 0\n",
    "    total_moves = 0\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        sample = test_data[i]\n",
    "\n",
    "        try:\n",
    "            ground_truth_move = sample[\"best_move\"]\n",
    "            allowed_squares_list = sample[\"allowed_squares\"]\n",
    "            \n",
    "            if isinstance(allowed_squares_list, list) and len(allowed_squares_list) >= 2:\n",
    "                ground_truth_allowed_square = {\n",
    "                    \"global_row\": allowed_squares_list[0],\n",
    "                    \"global_col\": allowed_squares_list[1]\n",
    "                }\n",
    "            else:\n",
    "                ground_truth_allowed_square = {\"global_row\": -1, \"global_col\": -1}\n",
    "            \n",
    "            legal_moves = sample[\"legal_moves\"]\n",
    "            unplayable_boards = sample[\"unplayable_boards\"]\n",
    "            image = sample[\"image\"].convert(\"RGB\")\n",
    "            player_turn = sample[\"player\"]\n",
    "            ascii_board = sample[\"ascii_board\"]\n",
    "            cot_text = sample[\"chain_of_thought\"]\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(f\"Skipping sample {i}: Missing required data field {e}.\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping sample {i}: General data processing error: {type(e).__name__}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            unplayable_list_str = format_squares_to_str(unplayable_boards)\n",
    "            legal_moves_str = format_moves_to_str(legal_moves)\n",
    "\n",
    "            system_content = (\n",
    "                f\"You are an expert Ultimate Tic-Tac-Toe player. \"\n",
    "                f\"Your goal is to identify the optimal, legal move based on the provided image and context. \"\n",
    "                f\"The final output must be **ONLY** a raw JSON object containing the chosen move.\"\n",
    "                f\"{{\\\"global_row\\\": r, \\\"global_col\\\": c, \\\"local_row\\\": lr, \\\"local_col\\\": lc}}.\"\n",
    "            )\n",
    "            \n",
    "            user_prompt_text = (\n",
    "                f\"Player: {player_turn} (X=Player 1, O=Player 2)\\n\"\n",
    "                f\"Analyze the board state in the image and determine the optimal move.\\n\\n\"\n",
    "                f\"--- BOARD CONTEXT ---\\n\"\n",
    "                f\"**Allowed/Active Board:** The global board highlighted in **BRIGHT GREEN** in the image is the current active board constraint. If this board is already won/tied, you must select any other available board (Free Play).\\n\"\n",
    "                f\"**Unplayable Boards:** The following Global Boards are already WON or TIED and cannot be played: {unplayable_list_str}\\n\\n\"\n",
    "                f\"--- ASCII VISUALIZATION ---\\n\"\n",
    "                f\"Use this labeled diagram to cross-reference the image coordinates (0, 1, 2) with the piece locations and board status:\\n\"\n",
    "                f\"{ascii_board}\\n\\n\"\n",
    "                f\"CRITICAL RULE: The target local cell (local_row, local_col) MUST be **EMPTY** on the global board (global_row, global_col).\\n\"\n",
    "                f\"CRITICAL RULE: All output coordinates (global_row, global_col, local_row, local_col) MUST be **0, 1 or 2**.\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping sample {i}: Error formatting prompt: {type(e).__name__}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": system_content}]},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"image\": image},\n",
    "                    {\"type\": \"text\", \"text\": user_prompt_text},\n",
    "                ],\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            inputs = processor.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=True,\n",
    "                add_generation_prompt=True,\n",
    "                return_dict=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=256,\n",
    "                    do_sample=False,\n",
    "                    temperature=0.1,\n",
    "                    top_p=0.9,\n",
    "                    use_cache=True\n",
    "                )\n",
    "            response_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "            # remove input prompt to get just the response\n",
    "            response_text = response_text.split(\"<|im_start|>assistant\\n\")[-1].strip()\n",
    "\n",
    "            # parse model's move\n",
    "            model_move = parse_move_from_text(response_text)\n",
    "            model_allowed_square = None\n",
    "            if model_move and all(k in model_move for k in [\"global_row\", \"global_col\"]):\n",
    "                model_allowed_square = {\n",
    "                    \"global_row\": model_move.get(\"global_row\"),\n",
    "                    \"global_col\": model_move.get(\"global_col\")\n",
    "                }\n",
    "\n",
    "            total_moves += 1\n",
    "            is_correct_move = compare_moves(model_move, ground_truth_move)\n",
    "            is_correct_allowed_square = compare_sqs(model_allowed_square, ground_truth_allowed_square)\n",
    "            is_legal = is_move_legal(model_move, legal_moves)\n",
    "            is_model_move_invalid = model_move_invalid(model_move)\n",
    "            similarity_score = move_similarity(model_move, ground_truth_move)\n",
    "\n",
    "            total_similarity_score += similarity_score\n",
    "\n",
    "            if is_correct_move:\n",
    "                correct_moves += 1\n",
    "\n",
    "            if is_correct_allowed_square:\n",
    "                correct_allowed_squares += 1\n",
    "\n",
    "            if is_legal:\n",
    "                legal_move_count += 1\n",
    "\n",
    "            if is_model_move_invalid:\n",
    "                invalid_model_move += 1\n",
    "\n",
    "            if i < 3:\n",
    "                print(f\"\\nSample {i} structure:\")\n",
    "                print(f\"  best_move type: {type(ground_truth_move)}, value: {ground_truth_move}\")\n",
    "                print(f\"  allowed_squares type: {type(allowed_squares_list)}, value: {allowed_squares_list}\")\n",
    "                print(f\"  converted allowed_square: {ground_truth_allowed_square}\")\n",
    "                print(f\"\\n--- Raw response from model for sample {i}: ---\")\n",
    "                print(f\"Response length: {len(response_text)}\")\n",
    "                print(f\"Response: {response_text}\")\n",
    "                print(\"--- End of raw response ---\")\n",
    "\n",
    "            if i < 5 or is_correct_move or not is_correct_move:\n",
    "                print(f\"\\nSample {i+1}\")\n",
    "                print(f\"Ground Truth Best Move: {ground_truth_move}\")\n",
    "                print(f\"Ground Truth Allowed Square: {ground_truth_allowed_square}\")\n",
    "                print(\"-\" * 100)\n",
    "                print(f\"Model Move: {model_move}\")\n",
    "                print(f\"Model Allowed Square: {model_allowed_square}\")\n",
    "                print(f\"Move Result: {'CORRECT MOVE' if is_correct_move else 'INCORRECT MOVE'}\")\n",
    "                print(f\"Allowed Square Result: {'CORRECT Square' if is_correct_allowed_square else 'INCORRECT Square'}\")\n",
    "                print(f\"Move Similarity Score: {similarity_score}\")\n",
    "                print(f\"Move Allowed?: {'Legal Move' if is_legal else 'Illegal Move'}\")\n",
    "                print(f\"{'Invalid Model Move' if is_model_move_invalid else ''}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {i}: {type(e).__name__}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if total_moves == 0:\n",
    "        print(\"WARNING: No samples were successfully processed!\")\n",
    "        return 0, 0, 0, 0, 0, 0\n",
    "    \n",
    "    move_accuracy = (correct_moves / total_moves) * 100\n",
    "    square_accuracy = (correct_allowed_squares / total_moves) * 100\n",
    "    legal_move_accuracy = (legal_move_count / total_moves) * 100\n",
    "    avg_similarity_score = total_similarity_score / total_moves\n",
    "    invalid_moves = invalid_model_move\n",
    "    return move_accuracy, square_accuracy, legal_move_accuracy, total_moves, invalid_moves, avg_similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423bef0-08d7-4127-b5c1-5d90887d4c1a",
   "metadata": {},
   "source": [
    "### Parsing Model Response to Evalute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550853aa-725e-4437-bc5f-d477f949729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_squares_to_str(squares_list):\n",
    "    \"\"\"Converts a list of global square dicts into a formatted string: [(r, c), (r, c), ...].\"\"\"\n",
    "    if not squares_list:\n",
    "        return \"[]\"\n",
    "    \n",
    "    formatted = []\n",
    "    for sq in squares_list:\n",
    "        if isinstance(sq, dict) and 'global_row' in sq and 'global_col' in sq:\n",
    "            formatted.append(f\"({sq['global_row']}, {sq['global_col']})\")\n",
    "    \n",
    "    return \"[\" + \", \".join(formatted) + \"]\"\n",
    "\n",
    "def format_moves_to_str(moves_list):\n",
    "    \"\"\"Converts a list of move dicts into a formatted string: [(gr, gc:lr, lc), ...].\"\"\"\n",
    "    if not moves_list:\n",
    "        return \"[]\"\n",
    "    \n",
    "    formatted = []\n",
    "    for move in moves_list:\n",
    "        if isinstance(move, dict) and all(k in move for k in [\"global_row\", \"global_col\", \"local_row\", \"local_col\"]):\n",
    "            formatted.append(f\"({move['global_row']},{move['global_col']}:{move['local_row']},{move['local_col']})\")\n",
    "    \n",
    "    return \"[\\n\" + \",\\n\".join(formatted) + \"\\n]\"\n",
    "\n",
    "def parse_move_from_text(text):\n",
    "    \"\"\"Parse move JSON from model response, more robust version\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    # multiple patterns to find the JSON\n",
    "    patterns = [\n",
    "        # Standard JSON pattern\n",
    "        r'\\{\\s*\"global_row\":\\s*\\d+,\\s*\"global_col\":\\s*\\d+,\\s*\"local_row\":\\s*\\d+,\\s*\"local_col\":\\s*\\d+\\s*\\}',\n",
    "        # Allow for extra whitespace and line breaks\n",
    "        r'\\{\\s*[\\n\\r]*\"global_row\"\\s*:\\s*\\d+\\s*,\\s*[\\n\\r]*\"global_col\"\\s*:\\s*\\d+\\s*,\\s*[\\n\\r]*\"local_row\"\\s*:\\s*\\d+\\s*,\\s*[\\n\\r]*\"local_col\"\\s*:\\s*\\d+\\s*[\\n\\r]*\\}',\n",
    "        # Try to find any JSON-like structure\n",
    "        r'\\{\\s*[\"\\']global_row[\"\\']\\s*:\\s*\\d+\\s*,\\s*[\"\\']global_col[\"\\']\\s*:\\s*\\d+\\s*,\\s*[\"\\']local_row[\"\\']\\s*:\\s*\\d+\\s*,\\s*[\"\\']local_col[\"\\']\\s*:\\s*\\d+\\s*\\}'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            move_str = match.group(0)\n",
    "            move_str = move_str.replace(\"'\", '\"').replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n",
    "            try:\n",
    "                return json.loads(move_str)\n",
    "            except json.JSONDecodeError as e:\n",
    "                continue\n",
    "    \n",
    "    # If no pattern matched, try to find any JSON and validate\n",
    "    try:\n",
    "        json_start = text.find('{')\n",
    "        json_end = text.rfind('}')\n",
    "        if json_start != -1 and json_end > json_start:\n",
    "            json_str = text[json_start:json_end+1]\n",
    "            data = json.loads(json_str)\n",
    "            required_keys = [\"global_row\", \"global_col\", \"local_row\", \"local_col\"]\n",
    "            if all(key in data for key in required_keys):\n",
    "                return data\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "def compare_moves(model_move, ground_truth_move):\n",
    "    # compare model move against ground truth\n",
    "    if model_move is None:\n",
    "        return False\n",
    "\n",
    "    keys = [\"global_row\", \"global_col\", \"local_row\", \"local_col\"]\n",
    "\n",
    "    try:\n",
    "        return all(model_move.get(k) == ground_truth_move.get(k) for k in keys)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def compare_sqs(model_square, ground_truth_square):\n",
    "    # compare model allowed square against ground truth allowed square\n",
    "    if model_square is None:\n",
    "        return False\n",
    "    \n",
    "    # Check if ground_truth_square is valid\n",
    "    if ground_truth_square is None:\n",
    "        return False\n",
    "    \n",
    "    # Check for the 'Any Board' case (-1, -1)\n",
    "    if ground_truth_square.get(\"global_row\") == -1:\n",
    "        # If Ground Truth is 'Any Board' (-1, -1), any board coordinate (0, 1, 2) \n",
    "        # is technically a valid target for the model's prediction.\n",
    "        return True \n",
    "\n",
    "    keys = [\"global_row\", \"global_col\"]\n",
    "\n",
    "    try:\n",
    "        return all(model_square.get(k) == ground_truth_square.get(k) for k in keys)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def is_move_legal(model_move, legal_moves):\n",
    "    if model_move is None:\n",
    "        return False\n",
    "    for m in legal_moves:\n",
    "        if (\n",
    "                model_move.get(\"global_row\") == m[\"global_row\"] and\n",
    "                model_move.get(\"global_col\") == m[\"global_col\"] and\n",
    "                model_move.get(\"local_row\") == m[\"local_row\"] and\n",
    "                model_move.get(\"local_col\") == m[\"local_col\"]\n",
    "        ):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def model_move_invalid(model_move):\n",
    "    if model_move is None:\n",
    "        return True\n",
    "    required_keys = ['global_row', 'global_col', 'local_row', 'local_col']\n",
    "    if not all(key in model_move for key in required_keys):\n",
    "        return True\n",
    "    coordinates = [\n",
    "        model_move.get('global_row'),\n",
    "        model_move.get('global_col'),\n",
    "        model_move.get('local_row'),\n",
    "        model_move.get('local_col'),\n",
    "    ]\n",
    "\n",
    "    for coord in coordinates:\n",
    "        # Check if coordinates are integers and within the 0, 1, 2 bounds\n",
    "        if not isinstance(coord, int) or coord not in {0, 1, 2}:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def move_similarity(model_move, ground_truth_move):\n",
    "    score = 0\n",
    "    if model_move is None:\n",
    "        return 0.0\n",
    "\n",
    "    keys = [\"global_row\", \"global_col\", \"local_row\", \"local_col\"]\n",
    "    if not all(key in model_move for key in keys):\n",
    "        return 0.0\n",
    "\n",
    "    if model_move[\"global_row\"] == ground_truth_move[\"global_row\"]:\n",
    "        score += 1\n",
    "    if model_move[\"global_col\"] == ground_truth_move[\"global_col\"]:\n",
    "        score += 1\n",
    "    if model_move[\"local_row\"] == ground_truth_move[\"local_row\"]:\n",
    "        score += 1\n",
    "    if model_move[\"local_col\"] == ground_truth_move[\"local_col\"]:\n",
    "        score += 1\n",
    "    return score / 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20973c9-77df-47f9-a44b-1e9c9917fe01",
   "metadata": {},
   "source": [
    "### Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b581ca12-9118-409d-b568-8fbe7c08d08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model: unsloth/Qwen3-VL-8B-Instruct-unsloth-bnb-4bit\n",
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth 2025.12.8: Fast Qwen3_Vl patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    NVIDIA A100 80GB PCIe MIG 1g.20gb. Num GPUs = 1. Max memory: 19.5 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Qwen3_Vl does not support SDPA - switching to fast eager.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57976aa5706d44fbb5bdf365251066fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Tokenizer loaded successfully\n",
      "\n",
      "Dataset size: 400\n",
      "Starting baseline evaluation on 5 samples\n",
      "\n",
      "Sample 0 structure:\n",
      "  best_move type: <class 'dict'>, value: {'global_row': 0, 'global_col': 2, 'local_row': 2, 'local_col': 2}\n",
      "  allowed_squares type: <class 'list'>, value: [0, 2]\n",
      "  converted allowed_square: {'global_row': 0, 'global_col': 2}\n",
      "\n",
      "--- Raw response from model for sample 0: ---\n",
      "Response length: 76\n",
      "Response: {\"global_row\": 0, \"global_col\": 2, \"local_row\": 1, \"local_col\": 0}<|im_end|>\n",
      "--- End of raw response ---\n",
      "\n",
      "Sample 1\n",
      "Ground Truth Best Move: {'global_row': 0, 'global_col': 2, 'local_row': 2, 'local_col': 2}\n",
      "Ground Truth Allowed Square: {'global_row': 0, 'global_col': 2}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model Move: {'global_row': 0, 'global_col': 2, 'local_row': 1, 'local_col': 0}\n",
      "Model Allowed Square: {'global_row': 0, 'global_col': 2}\n",
      "Move Result: INCORRECT MOVE\n",
      "Allowed Square Result: CORRECT Square\n",
      "Move Similarity Score: 0.5\n",
      "Move Allowed?: Legal Move\n",
      "\n",
      "\n",
      "Sample 1 structure:\n",
      "  best_move type: <class 'dict'>, value: {'global_row': 2, 'global_col': 1, 'local_row': 1, 'local_col': 1}\n",
      "  allowed_squares type: <class 'list'>, value: [2, 1]\n",
      "  converted allowed_square: {'global_row': 2, 'global_col': 1}\n",
      "\n",
      "--- Raw response from model for sample 1: ---\n",
      "Response length: 76\n",
      "Response: {\"global_row\": 2, \"global_col\": 1, \"local_row\": 1, \"local_col\": 1}<|im_end|>\n",
      "--- End of raw response ---\n",
      "\n",
      "Sample 2\n",
      "Ground Truth Best Move: {'global_row': 2, 'global_col': 1, 'local_row': 1, 'local_col': 1}\n",
      "Ground Truth Allowed Square: {'global_row': 2, 'global_col': 1}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model Move: {'global_row': 2, 'global_col': 1, 'local_row': 1, 'local_col': 1}\n",
      "Model Allowed Square: {'global_row': 2, 'global_col': 1}\n",
      "Move Result: CORRECT MOVE\n",
      "Allowed Square Result: CORRECT Square\n",
      "Move Similarity Score: 1.0\n",
      "Move Allowed?: Legal Move\n",
      "\n",
      "\n",
      "Sample 2 structure:\n",
      "  best_move type: <class 'dict'>, value: {'global_row': 2, 'global_col': 2, 'local_row': 1, 'local_col': 0}\n",
      "  allowed_squares type: <class 'list'>, value: [2, 2]\n",
      "  converted allowed_square: {'global_row': 2, 'global_col': 2}\n",
      "\n",
      "--- Raw response from model for sample 2: ---\n",
      "Response length: 76\n",
      "Response: {\"global_row\": 2, \"global_col\": 2, \"local_row\": 0, \"local_col\": 1}<|im_end|>\n",
      "--- End of raw response ---\n",
      "\n",
      "Sample 3\n",
      "Ground Truth Best Move: {'global_row': 2, 'global_col': 2, 'local_row': 1, 'local_col': 0}\n",
      "Ground Truth Allowed Square: {'global_row': 2, 'global_col': 2}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model Move: {'global_row': 2, 'global_col': 2, 'local_row': 0, 'local_col': 1}\n",
      "Model Allowed Square: {'global_row': 2, 'global_col': 2}\n",
      "Move Result: INCORRECT MOVE\n",
      "Allowed Square Result: CORRECT Square\n",
      "Move Similarity Score: 0.5\n",
      "Move Allowed?: Legal Move\n",
      "\n",
      "\n",
      "Sample 4\n",
      "Ground Truth Best Move: {'global_row': 0, 'global_col': 0, 'local_row': 2, 'local_col': 1}\n",
      "Ground Truth Allowed Square: {'global_row': 0, 'global_col': 0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model Move: {'global_row': 0, 'global_col': 0, 'local_row': 1, 'local_col': 0}\n",
      "Model Allowed Square: {'global_row': 0, 'global_col': 0}\n",
      "Move Result: INCORRECT MOVE\n",
      "Allowed Square Result: CORRECT Square\n",
      "Move Similarity Score: 0.5\n",
      "Move Allowed?: Legal Move\n",
      "\n",
      "\n",
      "Sample 5\n",
      "Ground Truth Best Move: {'global_row': 2, 'global_col': 0, 'local_row': 1, 'local_col': 2}\n",
      "Ground Truth Allowed Square: {'global_row': 2, 'global_col': 0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model Move: {'global_row': 2, 'global_col': 0, 'local_row': 0, 'local_col': 1}\n",
      "Model Allowed Square: {'global_row': 2, 'global_col': 0}\n",
      "Move Result: INCORRECT MOVE\n",
      "Allowed Square Result: CORRECT Square\n",
      "Move Similarity Score: 0.5\n",
      "Move Allowed?: Legal Move\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "BASELINE EVALUATION RESULTS\n",
      "Total samples: 5\n",
      "Baseline Move Accuracy: 20.00%\n",
      "Baseline Allowed Square Accuracy: 100.00%\n",
      "Average Move Similarity Score: 0.6\n",
      "Baseline Legal Move Accuracy: 100.00%\n",
      "Invalid Moves by Model (Hallucination/Out-of-bounds): 0 moves\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer, processor = load_vlm_model()\n",
    "    model.load_adapter(OUTPUT_DIR_V4)\n",
    "    \n",
    "    move_accuracy, square_accuracy, legal_move_accuracy, total_samples, invalid_moves, avg_similarity_score = evaluate_baseline(model, tokenizer, processor, DATASET_TEST_PATH)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"BASELINE EVALUATION RESULTS\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Baseline Move Accuracy: {move_accuracy:.2f}%\")\n",
    "    print(f\"Baseline Allowed Square Accuracy: {square_accuracy:.2f}%\")\n",
    "    print(f\"Average Move Similarity Score: {avg_similarity_score}\")\n",
    "    print(f\"Baseline Legal Move Accuracy: {legal_move_accuracy:.2f}%\")\n",
    "    print(f\"Invalid Moves by Model (Hallucination/Out-of-bounds): {invalid_moves} moves\")\n",
    "    print(\"\\n\" + \"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98a6d6-bbf0-4104-aae7-655a33fc2e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
