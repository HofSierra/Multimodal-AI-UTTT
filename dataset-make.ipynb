{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a9f1a38-156b-46ce-8569-7c214906b40c",
   "metadata": {},
   "source": [
    "### Install dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cda9472-4e8a-4555-9205-b3ac27512461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://nexus.iisys.de/repository/ki-awz-pypi-group/simple, https://pypi.org/simple\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.12/site-packages (11.3.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.12/site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.12/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Looking in indexes: https://nexus.iisys.de/repository/ki-awz-pypi-group/simple, https://pypi.org/simple\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow pandas datasets\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d6c208-7e9c-42a9-94eb-76d508c0fa5c",
   "metadata": {},
   "source": [
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd8d771-75de-4f1f-a954-50e94b32432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datasets import Dataset, Features, Image, Value, Sequence, Split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image as PILImage\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba198b04-4bba-460d-8a42-868223b4bee2",
   "metadata": {},
   "source": [
    "### Render ASCII Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77638146-7d22-4359-8239-90ea6c3b30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_win(grid):\n",
    "    grid = np.array(grid)\n",
    "\n",
    "    for i in range(3):\n",
    "\n",
    "        # Check each row\n",
    "        if grid[i, 0] == grid[i, 1] == grid[i, 2] != 0:\n",
    "            return grid[i, 0]\n",
    "\n",
    "        # Check each column\n",
    "        if grid[0, i] == grid[1, i] == grid[2, i] != 0:\n",
    "            return grid[0, i]\n",
    "\n",
    "    # Check both diagonals\n",
    "    if (grid[0, 0] == grid[1, 1] == grid[2, 2] != 0) or (grid[2, 0] == grid[1, 1] == grid[0, 2] != 0):\n",
    "        return grid[1, 1]\n",
    "\n",
    "    # Draw\n",
    "    if np.all(grid != 0):\n",
    "        return -1\n",
    "\n",
    "    # Ongoing\n",
    "    return 0\n",
    "\n",
    "def reconstruct_board_matrix(global_state_list):\n",
    "    board_matrix = [[[[0 for _ in range(3)] for _ in range(3)] for _ in range(3)] for _ in range(3)]\n",
    "    \n",
    "    global_status = [[0 for _ in range(3)] for _ in range(3)]\n",
    "\n",
    "    for cell in global_state_list:\n",
    "        g_r, g_c = cell['global_row'], cell['global_col']\n",
    "        l_r, l_c = cell['local_row'], cell['local_col']\n",
    "        player = cell['player']\n",
    "        \n",
    "        if 0 <= g_r < 3 and 0 <= g_c < 3 and 0 <= l_r < 3 and 0 <= l_c < 3:\n",
    "            board_matrix[g_r][g_c][l_r][l_c] = player\n",
    "\n",
    "    for g_r in range(3):\n",
    "        for g_c in range(3):\n",
    "            local_board = board_matrix[g_r][g_c]\n",
    "            status = check_win(local_board)\n",
    "            global_status[g_r][g_c] = status\n",
    "            \n",
    "    return board_matrix, global_status\n",
    "\n",
    "def get_unplayable_boards(global_status):\n",
    "    # all boards that have been won (1 or 2) or tied (3).\n",
    "    unplayable_boards = []\n",
    "    for g_r in range(3):\n",
    "        for g_c in range(3):\n",
    "            status = global_status[g_r][g_c]\n",
    "            if status != 0:\n",
    "                unplayable_boards.append({\n",
    "                    \"global_row\": g_r,\n",
    "                    \"global_col\": g_c\n",
    "                })\n",
    "    return unplayable_boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c554e8f1-7a5c-4c43-95f5-cc01692fdd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_ascii_board(global_state_list):\n",
    "    \"\"\"\n",
    "    Renders 9 separate 3x3 grids with explicit 0-1-2 axis labels.\n",
    "    Critical for small datasets to ground the coordinates visually.\n",
    "    \"\"\"\n",
    "    symbols = {0: '.', 1: 'X', 2: 'O'}\n",
    "\n",
    "    # Map (g_row, g_col, l_row, l_col) -> symbol\n",
    "    state_map = {}\n",
    "    for cell in global_state_list:\n",
    "        key = (cell['global_row'], cell['global_col'], cell['local_row'], cell['local_col'])\n",
    "        state_map[key] = symbols.get(cell['player'], '?')\n",
    "\n",
    "    board_sections = []\n",
    "\n",
    "    # Iterate through Global Boards\n",
    "    for g_r in range(3):\n",
    "        for g_c in range(3):\n",
    "            # Header with Global Coordinates\n",
    "            section = [f\"=== Global Board [Row {g_r}, Col {g_c}] ===\"]\n",
    "\n",
    "            # Column Axis Header (indent to match cell spacing)\n",
    "            section.append(\"    0 1 2\")\n",
    "            section.append(\"   -------\")\n",
    "\n",
    "            # Render rows with Row Axis Label\n",
    "            for l_r in range(3):\n",
    "                row_cells = []\n",
    "                for l_c in range(3):\n",
    "                    val = state_map.get((g_r, g_c, l_r, l_c), '.')\n",
    "                    row_cells.append(val)\n",
    "                # Format: \"0 | . X O\"\n",
    "                section.append(f\"{l_r} | \" + \" \".join(row_cells))\n",
    "\n",
    "            board_sections.append(\"\\n\".join(section))\n",
    "\n",
    "    return \"\\n\\n\".join(board_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9812cc2a-1644-43d2-858f-29973b36dcdf",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f0a26be-788c-4c97-855e-8aee2cecccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data():\n",
    "    from config import SYNTHETIC_LOG_FILE_PATH, DATASET_FOLDER, IMAGES_FOLDER\n",
    "    \n",
    "    if not os.path.exists(SYNTHETIC_LOG_FILE_PATH):\n",
    "        print(f\"Error: Input file '{SYNTHETIC_LOG_FILE_PATH}' not found.\")\n",
    "        print(\"Please ensure you are running this script from the 'ultimate-tic-tac-toe' folder.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Processing {SYNTHETIC_LOG_FILE_PATH}...\")\n",
    "\n",
    "    with open(SYNTHETIC_LOG_FILE_PATH, 'r') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                entry = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Skipping invalid JSON at line {line_num}\")\n",
    "                continue\n",
    "\n",
    "            full_img_path = entry.get(\"image path\")\n",
    "            if not os.path.exists(full_img_path):\n",
    "                print(f\"Warning: Image not found at {full_img_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                img_obj = PILImage.open(full_img_path).convert(\"RGB\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {full_img_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            global_state_list = entry.get(\"global state\", [])\n",
    "            \n",
    "            try:\n",
    "                board_matrix, global_status = reconstruct_board_matrix(global_state_list)\n",
    "                unplayable_boards = get_unplayable_boards(global_status)\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating board status for {full_img_path}: {e}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            ascii_board_str = render_ascii_board(global_state_list)\n",
    "            \n",
    "            yield {\n",
    "                \"image\": img_obj,\n",
    "                \"player\": entry.get(\"player\"),\n",
    "                \"global state\": global_state_list,\n",
    "                \"unplayable_boards\": unplayable_boards,\n",
    "                \"ascii_board\": ascii_board_str,\n",
    "                \"allowed_squares\": entry.get(\"allowed squares\"),\n",
    "                \"best_move\": entry.get(\"best move\"),\n",
    "                \"legal_moves\": entry.get(\"legal moves\", []),\n",
    "                \"chain_of_thought\": entry.get(\"chain of thought\", \"\")\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3e759f-9d52-42fb-be04-fe27eaf80b08",
   "metadata": {},
   "source": [
    "### Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "830ce0a8-fb3c-4ad6-b4cc-0e2b2f6f4948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88beccbea6a49b5a4d9ef578012288e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing logs/bot_moves_synthetic.jsonl...\n",
      "Loaded 4004 samples.\n",
      "Saving train split to uttt_qwen_dataset/train.parquet...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb0ba0138d3468c9097374e46beeb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test split to uttt_qwen_dataset/test.parquet...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebcdaf57b2e4b5c843e2bd0a8c951d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving evaluate split to uttt_qwen_dataset/evaluate.parquet...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a30a3b37da740dc98f66152beb62fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Success! Dataset created in: uttt_qwen_dataset\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    features = Features({\n",
    "        \"image\": Image(),\n",
    "        \"player\": Value(\"int32\"),\n",
    "        \"ascii_board\": Value(\"string\"),\n",
    "        \"chain_of_thought\": Value(\"string\"),\n",
    "        \n",
    "        \"best_move\": {\n",
    "            \"global_row\": Value(\"int32\"),\n",
    "            \"global_col\": Value(\"int32\"),\n",
    "            \"local_row\": Value(\"int32\"),\n",
    "            \"local_col\": Value(\"int32\"),\n",
    "        },\n",
    "        \n",
    "        \"allowed_squares\": Sequence(Value(\"int32\")), \n",
    "        \n",
    "        \"unplayable_boards\": [{\n",
    "            \"global_row\": Value(\"int32\"),\n",
    "            \"global_col\": Value(\"int32\"),\n",
    "        }],\n",
    "\n",
    "        \"legal_moves\": [{\n",
    "            \"global_row\": Value(\"int32\"),\n",
    "            \"global_col\": Value(\"int32\"),\n",
    "            \"local_row\": Value(\"int32\"),\n",
    "            \"local_col\": Value(\"int32\"),\n",
    "        }],\n",
    "        \n",
    "        \"global state\": [{\n",
    "            \"global_row\": Value(\"int32\"),\n",
    "            \"global_col\": Value(\"int32\"),\n",
    "            \"local_row\": Value(\"int32\"),\n",
    "            \"local_col\": Value(\"int32\"),\n",
    "            \"player\": Value(\"int32\"),\n",
    "        }]\n",
    "    })\n",
    "\n",
    "    ds = Dataset.from_generator(gen_data, features=features)\n",
    "\n",
    "    if len(ds) == 0:\n",
    "        print(\"No data loaded.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loaded {len(ds)} samples.\")\n",
    "\n",
    "    # 90% Train, 5% Test, 5% Val\n",
    "    train_testvalid = ds.train_test_split(test_size=0.2, seed=42)\n",
    "    test_eval = train_testvalid['test'].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "    final_dataset = {\n",
    "        'train': train_testvalid['train'],\n",
    "        'test': test_eval['train'],\n",
    "        'evaluate': test_eval['test']\n",
    "    }\n",
    "\n",
    "    from config import DATASET_FOLDER\n",
    "    os.makedirs(DATASET_FOLDER, exist_ok=True)\n",
    "\n",
    "    for split_name, dataset in final_dataset.items():\n",
    "        file_name = f\"{DATASET_FOLDER}/{split_name}.parquet\"\n",
    "        print(f\"Saving {split_name} split to {file_name}...\")\n",
    "        dataset.to_parquet(file_name)\n",
    "\n",
    "    print(\"\\nSuccess! Dataset created in:\", DATASET_FOLDER)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
